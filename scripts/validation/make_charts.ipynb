{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bd45db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "618cf5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_folders = ['../../output/run1/validation/summary-statistics', '../../output/run2/validation/summary-statistics', \n",
    "               '../../output/run3/validation/summary-statistics']\n",
    "graph_types = ['summary_observation', 'summary_action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e748235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   run         model           graph_type    method  Full Parse OK  \\\n",
      "0    1  llava-llama3  summary_observation       dpe           True   \n",
      "1    1  llava-llama3  summary_observation      i2kg           True   \n",
      "2    1  llava-llama3  summary_observation      d2kg           True   \n",
      "3    1  llava-llama3  summary_observation  d2kg-rag           True   \n",
      "4    1  llama4-scout  summary_observation       dpe           True   \n",
      "\n",
      "   Total triples in KG  Valid triples  Invalid triples  Distinct classes used  \\\n",
      "0                   17             17                0                      0   \n",
      "1                   31             31                0                      5   \n",
      "2                   99             99                0                      6   \n",
      "3                   89             89                0                      6   \n",
      "4                   35             35                0                      0   \n",
      "\n",
      "   Class Compliance  Class Coverage  Distinct properties used  \\\n",
      "0               0.0            0.00                         2   \n",
      "1               0.0            0.00                         9   \n",
      "2               1.0            0.75                         5   \n",
      "3               1.0            0.75                         8   \n",
      "4               0.0            0.00                         7   \n",
      "\n",
      "   Property Compliance  Property Coverage   \n",
      "0                 0.00                 0.0  \n",
      "1                 0.00                 0.0  \n",
      "2                 0.80                 1.0  \n",
      "3                 0.75                 1.0  \n",
      "4                 0.00                 0.0  \n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "\n",
    "model_pattern = re.compile(r'output/([^/]+)/')\n",
    "method_pattern = re.compile(r'graph/([^/]+)/kg\\.ttl') \n",
    "\n",
    "for run_index, folder in enumerate(run_folders, start=1):\n",
    "    for graph_type in graph_types:\n",
    "        file_path = os.path.join(folder, f\"{graph_type}.csv\")\n",
    "        df = pd.read_csv(file_path, index_col=False)\n",
    "        first_col = df.columns[0]\n",
    "        df.rename(columns={first_col: 'file_path'}, inplace=True)\n",
    "        df['file_path'] = df['file_path'].astype(str)\n",
    "        df['model'] = df['file_path'].apply(\n",
    "            lambda x: model_pattern.search(x).group(1) if model_pattern.search(x) else 'UNKNOWN'\n",
    "        )\n",
    "        df['method'] = df['file_path'].apply(\n",
    "            lambda x: method_pattern.search(x).group(1) if method_pattern.search(x) else 'UNKNOWN'\n",
    "        )\n",
    "        df['graph_type'] = graph_type\n",
    "        df['run'] = run_index\n",
    "        cols_order = ['run', 'model', 'graph_type', 'method'] + [\n",
    "            c for c in df.columns if c not in ['run', 'model', 'graph_type', 'method', 'file_path']\n",
    "        ]\n",
    "        df = df[cols_order]\n",
    "        all_dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "percentage_cols = [\n",
    "    col for col in merged_df.columns\n",
    "    if merged_df[col].astype(str).str.contains('%').any()\n",
    "]\n",
    "for col in percentage_cols:\n",
    "    merged_df[col] = (\n",
    "        merged_df[col].astype(str)\n",
    "        .str.replace('%', '', regex=False)\n",
    "        .replace('', '0')\n",
    "        .astype(float) / 100\n",
    "    )\n",
    "#merged_df.to_csv('merged_output.csv', index=False)\n",
    "print(merged_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
