{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e192779d",
   "metadata": {},
   "source": [
    "## SPARQL Query Notebook for Competency Questions on KGs\n",
    "\n",
    "This Jupyter Notebook provides a template for loading Knowledge Graphs (KGs) and executing SPARQL queries against them. \n",
    "\n",
    "These SPARQL queries are designed to answer specific Competency Questions (CQs), which are natural language questions that the KG is expected to answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b3fec",
   "metadata": {},
   "source": [
    "#### 1. Ontology Details\n",
    "\n",
    "KGs are built upon ontologies, which define the concepts, properties, and relationships for a specific domain or use case. \n",
    "\n",
    "For our use case, we have built the Personal Service Robots (PSR) - Task Ontology, with the aim to formally model the entities and relationships needed to personal service robots to perform tasks within an environment. \n",
    "\n",
    "The PSR-task Ontology is built on top of available standards, such as the: \n",
    " - Socio-physical Model of Activities ([SOMA](https://ease-crc.github.io/soma/)) Ontology\n",
    " - Descriptive Ontology for Linguistic and Cognitive Engineering ([DOLCE](https://www.loa.istc.cnr.it/dolce/overview.html))\n",
    "\n",
    "You can explore the ontology here: [PSR-Task Ontology](https://w3id.org/psr-task#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd9be4",
   "metadata": {},
   "source": [
    "#### 2. Loading the KGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bddabde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_graph_paths = [\n",
    "    # llava-llama3\n",
    "    \"../../output/llava-llama3/observation-graph/dpe/kg.ttl\",\n",
    "    \"../../output/llava-llama3/observation-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/llava-llama3/observation-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/llava-llama3/observation-graph/d2kg-rag/kg.ttl\",\n",
    "    # llama4-scout\n",
    "    \"../../output/llama4-scout/observation-graph/dpe/kg.ttl\",\n",
    "    \"../../output/llama4-scout/observation-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/llama4-scout/observation-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/llama4-scout/observation-graph/d2kg-rag/kg.ttl\",\n",
    "    # llama4-maverick\n",
    "    \"../../output/llama4-maverick/observation-graph/dpe/kg.ttl\",\n",
    "    \"../../output/llama4-maverick/observation-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/llama4-maverick/observation-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/llama4-maverick/observation-graph/d2kg-rag/kg.ttl\",\n",
    "    # gpt-o1\n",
    "    \"../../output/gpt-o1/observation-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/gpt-o1/observation-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/gpt-o1/observation-graph/d2kg-rag/kg.ttl\",\n",
    "    # gpt-4.1-nano\n",
    "    \"../../output/gpt-4.1-nano/observation-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/gpt-4.1-nano/observation-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/gpt-4.1-nano/observation-graph/d2kg-rag/kg.ttl\",\n",
    "]\n",
    "\n",
    "action_graph_paths = [\n",
    "    # llava-llama3\n",
    "    \"../../output/llava-llama3/action-graph/dpe/kg.ttl\",\n",
    "    \"../../output/llava-llama3/action-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/llava-llama3/action-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/llava-llama3/action-graph/d2kg-rag/kg.ttl\",\n",
    "    # llama4-scout\n",
    "    \"../../output/llama4-scout/action-graph/dpe/kg.ttl\",\n",
    "    \"../../output/llama4-scout/action-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/llama4-scout/action-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/llama4-scout/action-graph/d2kg-rag/kg.ttl\",\n",
    "    # llama4-maverick\n",
    "    \"../../output/llama4-maverick/action-graph/dpe/kg.ttl\",\n",
    "    \"../../output/llama4-maverick/action-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/llama4-maverick/action-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/llama4-maverick/action-graph/d2kg-rag/kg.ttl\",\n",
    "    # gpt-o1\n",
    "    \"../../output/gpt-o1/action-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/gpt-o1/action-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/gpt-o1/action-graph/d2kg-rag/kg.ttl\",\n",
    "    # gpt-4.1-nano\n",
    "    \"../../output/gpt-4.1-nano/action-graph/i2kg/kg.ttl\",\n",
    "    \"../../output/gpt-4.1-nano/action-graph/d2kg/kg.ttl\",\n",
    "    \"../../output/gpt-4.1-nano/action-graph/d2kg-rag/kg.ttl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2cda76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading observation graph from: ../../output/llama4-maverick/observation-graph/d2kg/kg.ttl\n",
      "Observation graph loaded. It contains 111 triples.\n",
      "Loading action graph from: ../../output/llama4-maverick/action-graph/d2kg/kg.ttl\n",
      "Action graph loaded. It contains 55 triples.\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, Literal, URIRef\n",
    "from rdflib.namespace import FOAF, XSD, RDF, RDFS\n",
    "\n",
    "observation_graph_path = \"../../output/llama4-maverick/observation-graph/d2kg/kg.ttl\"\n",
    "action_graph_path = \"../../output/llama4-maverick/action-graph/d2kg/kg.ttl\"\n",
    "\n",
    "observation_graph = Graph()\n",
    "action_graph = Graph()\n",
    "\n",
    "try:\n",
    "    print(f\"Loading observation graph from: {observation_graph_path}\")\n",
    "    observation_graph.parse(observation_graph_path, format='turtle')\n",
    "    print(f\"Observation graph loaded. It contains {len(observation_graph)} triples.\")\n",
    "\n",
    "    print(f\"Loading action graph from: {action_graph_path}\")\n",
    "    action_graph.parse(action_graph_path, format='turtle')\n",
    "    print(f\"Action graph loaded. It contains {len(action_graph)} triples.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading graphs: {e}\")\n",
    "    print(\"Please ensure the file paths are correct and the files exist.\")\n",
    "    print(\"Example usage: observation_graph.parse('data/my_observations.ttl', format='turtle')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0db12bf",
   "metadata": {},
   "source": [
    "#### 3. Competency Questions (CQs) and SPARQL Queries\n",
    "\n",
    "Now that our KGs are loaded, we can execute SPARQL queries against them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Competency Questions and their SPARQL Queries ---\n",
    "\n",
    "# Competency Question 1: \n",
    "query1 = \"\"\"\n",
    "SELECT DISTINCT ?s ?p\n",
    "WHERE {\n",
    "    ?s ?p ?o .\n",
    "}\n",
    "LIMIT 10\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
